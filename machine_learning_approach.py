# -*- coding: utf-8 -*-
"""Machine_Learning_Approach.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vv67KRtSWTZAIPvjfjOtq6V8GCJHTCQC

# Library Import
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

"""# Downloading Dataset"""

#Configuration environment
import os

os.environ['KAGGLE_USERNAME'] = "ankushdeshmukh12" # username from the json file
os.environ['KAGGLE_KEY'] = "273184adb0d2e046090044c1b9817039" # key from the json file

!kaggle datasets download -d kritikseth/fruit-and-vegetable-image-recognition

!unzip fruit-and-vegetable-image-recognition.zip

train_dir = 'train'
test_dir = 'test'
val_dir = 'validation'

image_size = 160

train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,
                                                                 image_size=(image_size, image_size))

val_data = tf.keras.preprocessing.image_dataset_from_directory(val_dir,
                                                                 image_size=(image_size, image_size))

test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,
                                                                 image_size=(image_size, image_size))

"""# Visualization"""

class_name = train_data.class_names
print(class_name)
print(len(class_name) , "Classes")

train_data

plt.figure(figsize=(10, 10))

for images, labels in train_data.take(1):
  for i in range(9):
    ax = plt.subplot(3,3,i+1)
    plt.imshow(images[i].numpy().astype('uint8'))
    plt.title(class_name[labels[i]])
    plt.axis('off')

"""# PreProcessing"""

for image_batch, label_batch in train_data:
  print("Image Batch Shape :", image_batch.shape)
  print("Image Labels Shape :", label_batch.shape)
  break
  
print("\nImage before formating : ")
first_image = image_batch[0]
print(np.min(first_image), np.max(first_image))

first_image.shape

def format(image, label):
  image = tf.cast(image, tf.float32)
  image = image/255.0
  return image, label

train = train_data.map(format)
validation = val_data.map(format)
test = test_data.map(format)

for image_batch, label_batch in train:
  print("Image Batch Shape :", image_batch.shape)
  print("Image Labels Shape :", label_batch.shape)
  break
  
print("\nImage after formating : ")
first_image = image_batch[0]
print(np.min(first_image), np.max(first_image))

# For Traditional Machine Learning Approach we do not need batches
# Appending all of the batches
train_images = []
train_labels = []
for images, labels in train:
    for image in images:
        train_images.append(image)
    for label in labels:
        train_labels.append(label)
        
train_images = np.array(train_images)
train_labels = np.array(train_labels)
print("Train Images Shape :", train_images.shape)
print("Train Labels Shape :", train_labels.shape)

val_images = []
val_labels = []
for images, labels in validation:
    for image in images:
        val_images.append(image)
    for label in labels:
        val_labels.append(label)

val_images = np.array(val_images)
val_labels = np.array(val_labels)
print("Validation Images Shape :", val_images.shape)
print("Validation Labels Shape :", val_labels.shape)

test_images = []
test_labels = []
for images, labels in test:
    for image in images:
        test_images.append(image)
    for label in labels:
        test_labels.append(label)

test_images = np.array(test_images)
test_labels = np.array(test_labels)
print("Test Images Shape :", test_images.shape)
print("Test Labels Shape :", test_labels.shape)

"""# KNN Classifier"""

# Hyper Parameter Tuning
from sklearn.neighbors import KNeighborsClassifier

index = []
accuracies = []

for n in range(1, 11):
    # Train KNN model
    knn = KNeighborsClassifier(n_neighbors=n)
    knn.fit(train_images.reshape(train_images.shape[0], -1), train_labels)

    # Evaluate model
    val_pred = knn.predict(val_images.reshape(val_images.shape[0], -1))
    accuracy = np.mean(val_pred == val_labels)
    print("For n =", n)
    print("Validation Accuracy:", accuracy)

    # For Graph Plot
    index.append(n)
    accuracies.append(accuracy)

# Visualization
print()
plt.plot(index, accuracies)
plt.xlabel("N_Neighbours")
plt.ylabel("Accuracy")
plt.title("KNN Hyperparameter Tuning")
plt.show()

# Tuned KNN model
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(train_images.reshape(train_images.shape[0], -1), train_labels)

# Evaluate model
val_pred = knn.predict(val_images.reshape(val_images.shape[0], -1))
accuracy = np.mean(val_pred == val_labels)
print("Validation Accuracy:", accuracy)

test_pred = knn.predict(test_images.reshape(test_images.shape[0], -1))
accuracy = np.mean(test_pred == test_labels)
print("Testing Accuracy:", accuracy)

"""# RandomForestClassifier Model"""

# Hyper Parameter Tuning
from sklearn.ensemble import RandomForestClassifier

index = []
accuracies = []

for n in range(5,40, 5):
  # Train RandomForestClassifier
  RF_model = RandomForestClassifier(n_estimators = n, random_state = 42)
  RF_model.fit(train_images.reshape(train_images.shape[0], -1), train_labels)

  # Evaluate model
  val_pred = RF_model.predict(val_images.reshape(val_images.shape[0], -1))
  accuracy = np.mean(val_pred == val_labels)
  print("For n =", n)
  print("Validation Accuracy:", accuracy)

  # For Graph Plot
  index.append(n)
  accuracies.append(accuracy)

# Visualization
print()
plt.plot(index, accuracies)
plt.xlabel("N_Estimators")
plt.ylabel("Accuracy")
plt.title("RandomForestClassifier Hyperparameter Tuning")
plt.show()

# Tuned RandomForestClassifier Model
RF_model = RandomForestClassifier(n_estimators = 25, random_state = 42)

RF_model.fit(train_images.reshape(train_images.shape[0], -1), train_labels)

# Evaluate model
val_pred = RF_model.predict(val_images.reshape(val_images.shape[0], -1))
accuracy = np.mean(val_pred == val_labels)
print("Validation Accuracy:", accuracy)

test_pred = RF_model.predict(test_images.reshape(test_images.shape[0], -1))
accuracy = np.mean(test_pred == test_labels)
print("Testing Accuracy:", accuracy)

"""# SVM Model"""

# SVM model
from sklearn import svm
SVM_model = svm.SVC(decision_function_shape='ovo')  #For multiclass classification
SVM_model.fit(train_images.reshape(train_images.shape[0], -1), train_labels)

# Evaluate model
val_pred = SVM_model.predict(val_images.reshape(val_images.shape[0], -1))
accuracy = np.mean(val_pred == val_labels)
print("Validation Accuracy:", accuracy)

test_pred = SVM_model.predict(test_images.reshape(test_images.shape[0], -1))
accuracy = np.mean(test_pred == test_labels)
print("Testing Accuracy:", accuracy)

"""# Naive Bayes Model"""

# Naive Bayes model
from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(train_images.reshape(train_images.shape[0], -1), train_labels)
 
# Evaluate model
val_pred = gnb.predict(val_images.reshape(val_images.shape[0], -1))
accuracy = np.mean(val_pred == val_labels)
print("Validation Accuracy:", accuracy)

test_pred = gnb.predict(test_images.reshape(test_images.shape[0], -1))
accuracy = np.mean(test_pred == test_labels)
print("Testing Accuracy:", accuracy)

"""# Logistic Regression Model"""

# Logistic Regression Model
from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(train_images.reshape(train_images.shape[0], -1), train_labels)


# Evaluate model
val_pred = model.predict(val_images.reshape(val_images.shape[0], -1))
accuracy = np.mean(val_pred == val_labels)
print("Validation Accuracy:", accuracy)

test_pred = model.predict(test_images.reshape(test_images.shape[0], -1))
accuracy = np.mean(test_pred == test_labels)
print("Testing Accuracy:", accuracy)

"""# Ensemble Learning"""

# Voting Classifier
from sklearn.ensemble import VotingClassifier
estimators = []
estimators.append(('RF', RF_model))
estimators.append(('KNN', knn))
estimators.append(('LR', model))

model_voting_classifier = VotingClassifier(estimators=estimators)
model_voting_classifier.fit(train_images.reshape(train_images.shape[0], -1), train_labels)


# Evaluate model
val_pred = model_voting_classifier.predict(val_images.reshape(val_images.shape[0], -1))
accuracy = np.mean(val_pred == val_labels)
print("Validation Accuracy:", accuracy)

test_pred = model_voting_classifier.predict(test_images.reshape(test_images.shape[0], -1))
accuracy = np.mean(test_pred == test_labels)
print("Testing Accuracy:", accuracy)

"""# Prediction Analysis"""

import tensorflow as tf

# read the image
img = tf.io.read_file('unlabelled/Untitled.jpeg')
img = tf.image.decode_image(img, channels=3)
img = tf.image.resize(img, (160, 160))


# normalize the pixel values to be between 0 and 1
img = tf.cast(img, tf.float32)
img = img / 255.0
img = np.array(img)


pred = knn.predict(img.reshape(1, -1))
print("Knn Prediction :", class_name[pred[0]])
print()

pred = RF_model.predict(img.reshape(1, -1))
print("Random Forests Prediction :", class_name[pred[0]])
print()

pred = model.predict(img.reshape(1, -1))
print("Logistics Regression Prediction :", class_name[pred[0]])
print()

pred = model_voting_classifier.predict(img.reshape(1, -1))
print("Voting Classifier Prediction :", class_name[pred[0]])
print()

print("Image : ")
img = img * 255.0
plt.imshow(img.astype('uint8'))
plt.axis('off')

"""# API for Recipes"""

import requests

l = ['apples', 'mango']
s = ""
for i in l:
  s += ","
  s += i
s = s[1:]
print("Recipes with", s, ":")
print()

url = 'https://api.edamam.com/search?q='+s+'&app_id=1ea1869e&app_key=01d121c1656be3c531afecc7da3af3eb'
response = requests.get(url)

if response.status_code == 200:
    recipes = response.json()['hits']
    count = 1
    for recipe in recipes:
        print(count, ")" ,recipe['recipe']['label'], ":")
        ingr = ""
        for i in recipe['recipe']['ingredientLines']:
          ingr += ("    "+i+"\n")
        print("  Ingredients : ")
        print(ingr)
        print("  Image : ", recipe['recipe']['image'])
        print()
        print("  Source : ", recipe['recipe']['source'])
        print()
        count += 1
else:
    print('Failed to get recipes:', response.status_code)

"""# Saving the Model"""

# Saving the model
import pickle
pickle.dump(model_voting_classifier, open('model.pkl', 'wb'))

# Loading the model
img = img / 255.0
pickled_model = pickle.load(open('model.pkl', 'rb'))
pred = pickled_model.predict(img.reshape(1, -1))
print("Prediction :", class_name[pred[0]])

"""# Evaluation Metrics"""

test_pred = model_voting_classifier.predict(test_images.reshape(test_images.shape[0], -1))

from sklearn.metrics import precision_score

print("Precision of the Model : ", precision_score(test_labels, test_pred, average="macro"))

from sklearn.metrics import recall_score

print("Recall of the Model : ", recall_score(test_labels, test_pred, average="macro"))

from sklearn.metrics import f1_score

print("F1-Score of the Model : ", f1_score(test_labels, test_pred, average="macro"))

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(test_labels, test_pred)

print("Confusion Matrix : ")
print(cm)
print()

import seaborn as sns
sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=class_name, yticklabels=class_name)

# Add labels and title to the plot
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()